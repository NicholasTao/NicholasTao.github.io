## 模块设计

#### 升级前信息收集/统一数据接口 

新框架在升级前新增了升级前信息收集工步。主要收集两种数据：

1. 部署数据:
   1. 每个节点部署了哪些组件，组件升级前的版本号是多少
   2. 节点是管理节点、计算节点、宿主机、网络节点还是SDI节点
   3. 环境的网络分组情况
2. 升级数据：
   1. 本次升级工程涉及哪些升级包，以及相关的升级参数：对应的组件、版本号、rpm列表、是否需要重启...

部署数据从cps接口获取，升级数据通过升级描述文件获取。

升级过程中其它模块通过统一低代码接口调用。

这个新模块的优点是，避免了每个工步单独实现数据处理。详见[[旧框架设计-内部数据管理]](#内部数据管理)

这些数据都是静态数据，避免了

```

```



### 下发器模块设计

![image-20221103141111707](新升级框架外部汇报.assets/image-20221103141111707.png)



输入: Mission

执行：

1. 将Mission中的任务按顺序下发给执行器
2. 获取所有任务执行结果并返回

输出: Mission执行结果

```
# 情况1，所有Task成功。输出如下
{
	done: [t1, t2...]
}

# 情况1，执行中出现Task失败。输出如下
{
	done: [t1, t2...]， # 已执行，且成功
	fail: [t3, t4],     # 已执行，但失败
	undo: [t5, t6, ...] # 未执行
}
```



#### 执行过程

1. 从当前计划书获取当前计划，称为Mission。将当前计划书传给Mission执行器。

2. Mission执行器依次将Mission中的子BatchJob传给BatchJob执行器。

   > Mission是BatchJob的1维数组，其中的BatchJob顺序执行

3. BatchJob执行器将BatchJob的子Job发送给对应节点(通过Job发送器)

4. 下发任务完成后，BatchJob执行器将BatchJob的子Task传给Task监控器监控。

5. Task监控器会定时查询数据库，检查是否所有Task完成。完成后通知BatchJob执行器。

6. BatchJob执行器将BatchJob执行结果上报给Mission执行器。

7. Mission执行器重复2-6，直到Mission执行完成

### 编排器设计

![image-20221103152319570](新升级框架外部汇报.assets/image-20221103152319570.png)

#### Task生成器

根据升级信息和升级逻辑书，生成升级工程的所有升级任务。示例如下：

```
# 输入
部署数据：节点A, 上面部署了组件X, Y, Z; 节点B，上面部署了X
升级数据：X, Y需要重启升级
逻辑书: 重启升级的instance需要做5个动作dispatch, check, stop, uprpm, start

# 输出
A_X_dispatch, A_X_check, A_X_stop, A_X_uprpm, A_X_start
A_Y_dispatch, A_Y_check, A_Y_stop, A_Y_uprpm, A_Y_start
B_X_dispatch, B_X_check, B_X_stop, B_X_uprpm, B_X_start
```

#### Task编排器

根据升级信息和所有Task，生成任务计划书。示例如下：

```
# 输入
部署数据：节点A, 上面部署了组件X, Y, Z; 节点B，上面部署了X
升级数据：X, Y需要重启升级
逻辑书: 重启升级的instance需要做5个动作dispatch, check, stop, uprpm, start

# 输入
所有Task：
A_X_dispatch, A_X_check, A_X_stop, A_X_uprpm, A_X_start
A_Y_dispatch, A_Y_check, A_Y_stop, A_Y_uprpm, A_Y_start
B_X_dispatch, B_X_check, B_X_stop, B_X_uprpm, B_X_start
逻辑书：
1. 同时分发下载所有升级包
2. 同时检查所有组件
3. 先关闭X, 再关闭Y
4. 同时升级所有rpm包
5. 先开启Y，再开启X

# 输出
[
	[[[A_X_dispatch]], [[A_Y_dispatch]], [[B_X_dispatch]]],
	[[[A_X_check]], [[A_Y_check]], [[B_X_check]]],
	[[[A_X_stop]], [[B_X_stop]]],
	[[[A_Y_stop]]],
	[[[A_X_uprpm, A_Y_uprpm]], [[B_X_uprpm]]],
	[[[A_Y_start]]],
	[[[A_X_start]], [[B_X_start]]],
]
# 计划书数据结构设计见附录
```

#### 编排器优点

1. 便于开发：编排和执行逻辑解耦，有关执行顺序的升级新特性只需要修改逻辑书。新特性包括但不限于：管理面备区升级，网络单独升级

2. 便于测试：

   可以手动或脚本生成任务计划书，进行特化的升级测试，如：

   ```
   # 手动编写计划书，跳过检查阶段，只升级节点A的X组件
   [[[
   	[A_X_dispatch],
   	[A_X_stop],
   	[A_X_uprpm],
   	[A_X_start]
   ]]]
   ```

   可以临时添加任务，或调整任务顺序。如添加新任务，任务中构造异常，以自动化测试异常情况下的升级。

3. 便于检视

   可以通过检视逻辑书或计划书的方式，详细了解升级顺序。如：

   1. 组件开发人员，可自行确认升级两个组件关闭的先后顺序
   2. 了解网络节点的分批情况(网络节点必须分成几批升级)

### 截取器设计

当前升级实际操作中，升级不是自动化一次性跑完的。需要根据前端命令，一次执行部分任务。

截取器是根据前端命令和全局计划书，截取当前计划书的模块。

主要操作是根据前端命令从全局计划书中找到相应的任务，再保留任务间的顺序生成当前计划书。

```
# 前端命令升级节点A组件Y,节点B组件X
# 输入全局计划书
[
	[[[A_X_dispatch]], [[A_Y_dispatch]], [[B_X_dispatch]]],
	[[[A_X_check]], [[A_Y_check]], [[B_X_check]]],
	[[[A_X_stop]], [[B_X_stop]]],
	[[[A_Y_stop]]],
	[[[A_X_uprpm, A_Y_uprpm]], [[B_X_uprpm]]],
	[[[A_Y_start]]],
	[[[A_X_start]], [[B_X_start]]],
]

# 输出当前计划书(A_X, dispatch, check等无关任务都被剔除了)
[
	[[[B_X_stop]]],
	[[[A_Y_stop]]],
	[[[A_Y_uprpm]], [[B_X_uprpm]]],
	[[[A_Y_start]]],
	[[[B_X_start]]],
]
```

另外，必要情况下，截取时可以更改任务顺序。如全局计划书中先升级节点12再升级节点34，截取时外部命令要求先升级节点13再升级24，则截取器可以调整顺序(这项功能常用于网络自定义分批升级)。

#### 截取器优点

当前计划书也具有可读、可更改的特点，可参考上文[[编排器优点]](#编排器优点)关于全局计划书的描述。

## 旧框架设计

升级逻辑应该是简单的，实现是过分复杂的。

### 内部数据管理

动态数据多，导致开发测试定位困难

例子1: 现网出现问题，定位到函数function，但是无法确定哪一行出错函数func获取了。

```python
# 函数function出错, 待定位
def function():
	a = cache_a.get_a()
	b = cache_b.get_b()
	c = cache_c.get_c()
	return a - b + c;
```

其中三个从内存获取数据的方法，每个在前文都有很多修改逻辑，都可能出错。

```python
# 前文涉及到数据a的逻辑
cache_a.set_a(dict_x)
cache_a.update_a(dict_y)
cache_a.update_a(dict_z)
```



```python
def function():
	a = dao.get_a()
	b = dao.get_b()
	c = dao.get_c()
	return a - b + c;

# 前文涉及到数据a的逻辑
dao.init() # 生成了raw_a, raw_b, raw_c
def init():
    generate_raw_a()
    generate_raw_b()
    generate_raw_c()
    
def get_a()
	return const_
```



1. 

2. 依赖

![image-20221103100528166](新升级框架外部汇报.assets/image-20221103100528166.png)

大部分业务逻辑依赖于多个数据接口实现，造成了开发、测试、定位困难



```python
# 
def function():
	a = model_a.get_a()
	b = model_b.get_b()
	c = model_c.get_c()
	return a + b + c;

def test_function():
    model_a.set_a()
    model_b.set_b()
    model_c.set_c()
    function()
```




## 工程进度

### 详细设计		已完成(2周)

新升级框架整体架构、模块划分、核心模块交互、主要数据结构等设计
模块开发顺序、测试方案等设计

### 设计书评审		进行中(6周)

设计书内部评审

### 模块分工		

按模块分工给具体开发人员，主要有以下四个模块

1. 升级脚本(执行具体升级任务: 下载rpm, 启停组件, 升级rpm等)
2. server任务系统开发(升级任务的顺序编排和下发)
3. client任务执行器开发(接收server下发的命令, 调用相关组件)
4. 外部数据接口(对cps\nova\swift\zookeeper\gaussdb), 内部数据接口(server/client通信)

### 分模块设计		(1周)

与各个模块开发人员对齐模块设计方案和接口

### 工程开发		(15人月)

四大模块并行开发 -> 联调 -> 对接ci\端到端环境验证

# FAQ

### 新框架能否完成升级任务？

可以，因为

1. 升级工程能被任务计划书完整描述。包括细粒度的升级任务、任务间的顺序和串并行关系。
2. 任务计划书可以被任务下发执行器依序执行。

## 为什么重写不是重构？

## 旧框架有什么问题？

### 代码问题

### 架构问题

# 附录

## 主要数据结构

#### 任务(Task) 

最小的原子化升级任务，一般是指对某个instance进行某个操作。如“节点1的nova-api升级rpm包”

构成元素是host_target_action:

1. host: 

   一般指执行的节点, 如“host1”。全局任务下host为特殊节点“upg-server”。

2. target: 

   任务对象，一般为某个template，如“nova-api”。

3. action: 

   任务动作，如“stop”，“up-rpm”，“start”。

   

   上文“节点1的nova-api升级rpm包”可表示为“host1_nova-api_up-rpm”

   action是原子化细粒度不可分割的。

   > 旧框架: 
   >
   > 	任务是粗粒度、非原子性的。如“升级执行”任务，包括了多批组件的启停、rpm升级、修改配置等多个小任务。
   > 	
   > 	分批关闭组件 -> 修改配置 -> rpm升级 -> 分批开启组件
   >
   > 假如rpm升级工步失败，
   >
   > 	1.	系统只显示“升级执行失败”，需要排除日志才能定位出错点
   > 	
   > 	2.	重试时，需要先重试分批关闭组件、修改配置两个前置工步，才能重试rpm升级
   > 	3.	重试时，pkg内组件无法区分。例如控制节点FusionPlatFrom包内20个组件, 只有一个组件失败了，必须20个组件一起重试
   >
   > 新框架:
   >
   > 	任务是细粒度、原子性的。任务要么全部成功，要么全部失败。
   >
   > 假如rpm升级工步失败，
   >
   >       	1.	系统直接显示“A节点B组件rpm升级失败”
   >                 	2.	重试时，可以直接重试“A节点B组件rpm升级失败”，无需冗余重试前置工步和相关组件
   >
   > 原子性的其它优点这里不赘述。

#### 节点任务(Job)

某个节点一次执行的任务。结构上是Task的2维数组。Job描述了子任务内容、执行顺序和串并行情况。

为了性能考虑，upg-server会对一个upg-client批量下发任务。

```
"""节点任务Job数据结构示例"""
[
	[h1_stop_nova-api, h1_stop_swift-store],
	[h1_uprpm_nova-api, h1_uprpm_swift-store],
	[h1_start_nova-api, h1_start_swift-store]
]
```

如上图，节点h1升级nova-api, swift-store共有6个任务。需要先并行执行关闭2个组件，完成后再并行升级2个组件rpm，完成后再并行打开2个组件。

#### 计划书(Mission)

某个节点一次执行的任务。结构上是Task的4维数组, Job的2维数组。Mission描述了子Job内容、执行顺序和串并行情况。

```
"""节点任务Job数据结构示例"""
[
	[h1_execute_manage_job, h2_execute_manage_job],
	[h1_execute_hostos, h2_execute_hostos],
	[h1_effect_hostos, h2_effect_hostos]
]
```

#### 全局计划书

所有包含升级所有Task的内容和执行顺序

#### 当前计划书

根据外部命令从全局计划书截取的，当前需要执行的Task的内容和执行顺序

## 为什么做新框架？

### 新框架目标

1. 大规模性能提高至10k以上							原因: 优化了升级框架内部瓶颈点
2. 现网Bug减少至1/2										原因: 代码可信整改
3. 升级框架新需求开发工作量减少至1/3		原因: 代码架构优化
4. 周边组件测试时间缩短至1/4						原因: 新特性，细粒度上下文无关的升级回退

## The Header

[Link to Header](#the-header)

### 新增的特性

1. 灵活升级
   细粒度任务独立回退升级, 任意小工步升级失败后可以独立回退。并重试或添加规避代码后重试

   单工步调试：开发过程中可以单工步调试，且无需依赖前后工步。如单独调试升级配置转换

   详细设计: [灵活升级特性设计](#灵活升级特性设计)

   旧框架实现对比: [[旧框架设计]](#旧框架设计)

   影响: 开发中的测试效率, 生产中的规避效率

   

2. 并行升级
   工程一升级AB组件的同时，工程二可以并行升级无依赖的CD组件

   详细设计: [并行升级特性设计](#并行升级特性设计)

   旧框架实现对比: [[旧框架设计]](#旧框架设计)

   影响: 升级效率，升级灵活性

   

3. 多版本升级
   支持一个版本的组件升级到不同版本，如控制节点升级OS，计算节点不升级OS。控制节点升级到X版本Nova，计算节点升级到Y版本Nova

   

4. N-X升级
   支持N-X升级的升级框架支持
   a)	提供管理面备区升级能力，管理组件随hostos在备区升级后重启生效；同时保留管理面重启单独组件升级方式

   

5. 可视化升级(未来特性)
   升级前可以生成整个升级计划书，供用户和技术人员检视，并可以根据需要灵活修改。升级过程不再是盲盒

### 改善的特性

1. 并行化
   编排、任务下发、任务上报接收、任务执行、查询进度都可以用独立进程执行，其中任务下发、任务上报接收、任务执行、查询进度各自可以用并发多进程
2. 大规模
   可以支持10k节点升级，升级框架本身不再是性能瓶颈。提供相关性能分析接口，在开发过程中就能自动分析各升级组件和外部接口性能。

### 主要改动点

1. 统一数据收集
2. 细粒度升级
3. 解耦

### 新框架对比

详细见下文“新旧框架对比”章节

> 好的架构逻辑清晰，坏的架构一言难尽
>
> 本文可以详细描述新框架的架构逻辑。但是无法详细说明旧框架的架构逻辑，原因就是旧框架是混乱的无法简单梳理清楚的。
>
> 既然旧框架无法说明清楚，如何保证新框架和旧框架的一致？
>
> 升级框架是一个服务，只要对外接口和对外特性保持一致即可。内部实现的变更是不需要一一对应验证的。

## 新框架设计原理

1. 升级工程是由多个小任务组成的。
2. 升级就是单个任务的执行内容和多个任务的执行顺序组成。
3. 升级是简单的。（代码量15k，核心逻辑"启停、升级rpm"）

## 新框架是怎么样的？

### 模块交互

![升级模块详细流程图](新升级框架外部汇报.assets/升级模块详细流程图.png)

1. 升级前编排生成全局计划书，包含了所有升级任务的内容、执行顺序和串并行信息。
2. 升级时根据外部升级命令截取相应的升级任务生成当前计划书。
3. 通过(upg-server)任务下发器下发当前计划书给对应的(upg-client)任务执行器。
4. 任务执行器根据任务内容调用相应任务脚本。
5. 任务脚本执行完成后，任务执行器上报任务给任务状态接收器，接收器固化结果在数据库中，下发器监控到任务完成后继续执行下一批任务。
6. 循环3-5直到当前计划书中全部任务完成。

详细见下文[[模块设计]](#模块设计)章节

与旧框架对比见下文[旧框架图]

### 升级顺序

与旧框架相同, 按照以下顺序

> 分发 -> 检查 -> 管理面升级 -> 网络升级 -> 数据面升级-> 提交

这部分逻辑写在新框架的[[逻辑书]](# 逻辑书详细设计)中, 未来可以通过改变逻辑书来修改升级顺序。

### 对外接口/升级脚本

与旧框架保持相同

## 新框架如何完成升级任务？

### 整体流程

[信息收集 -> 依次]

Note新增模块

<!--新增前置信息收集模块-->

### 端到端流程

以最典型的升级大任务--管理面升级为例

![image-20221101163005340](新升级框架外部汇报.assets/image-20221101163005340.png)

1. 接收外部升级命令"管理面升级执行"

2. 根据命令[[任务截取器]](#任务截取器详细设计)从[[全局计划书]](#全局计划书详细设计)截取[[当前计划书]](#当前计划书详细设计)，此时当前计划书的内容为

   ```
   [
   	[节点A关闭第1批组件, 节点B关闭第1批组件, ...],
   	[节点A关闭第2批组件, 节点B关闭第2批组件, ...],
   	...
   	[组件X修改配置, 组件Y修改配置, ...],
   	[节点A升级(XY...)组件rpm, 节点B升级(YZ...)组件rpm...]
   	[节点A开启第1批组件, 节点B开启第1批组件, ...],
   	[节点A开启第2批组件, 节点B开启第2批组件, ...],
   	...
   ]
   # 注意到这里是2维数组, 内层数组表示里面的任务是同一批并行执行的，外部数组表示每批任务是串行执行的
   ```

3. 任务下发器下发批节点任务。首先下发的是"关闭第1批组件"

   ```
   [节点A关闭第1批组件, 节点B关闭第1批组件, ...]
   ```

   既将"节点A关闭第1批组件"下发给节点A，"节点B关闭第1批组件"下发给节点B...

4. 任务执行器接收下发的节点任务。以节点A为例，此时节点任务"节点A关闭第1批组件"的内容是

   ```
   [
   	[节点A关闭nova-api, 节点A关闭swift-ngnix, ...]
   	[节点A关闭nova-console, ... ]
   	...
   ]
   # 注意到这里是2维数组, 内层数组表示里面的任务是同一批并行执行的，外部数组表示每批任务是串行执行的
   ```

5. 任务执行器会安装顺序和串并行情况依次调用相应的任务脚本

## 新旧框架对比

# 详细设计

## 特性设计

### 灵活升级特性设计

升级工程是由一个个小粒度的任务按照顺序组成的。只要做到任意单任务的升级回退，就可以完成任意组合的升级回退。

场景二:	A节点升级后调测失败

		旧框架:


​			

场景一:

	现象：现网升级中，某个组件在某个节点数据割接出现了问题，导致组件启动后异常。需要先恢复环境，再规避继续升级。
	
	旧框架: 
	
		方法1: 整体回退，整个环境回退到升级前。再修改配置转换逻辑代码，再次从头走升级后逻辑。时间太长，现网基本不会采用。
	
		预期规避时间: 10小时以上
	
		方法2: 人工处理割接后的数据，将数据逐一改成正确数据。规避时间长，人工操作易出错。
	
		预期规避时间: 30分钟                 
	
	新框架：
	
		单独回退该组件该节点的数据割接任务。修改配置转换逻辑代码。重试数据割接任务。
	
		由于只需要回退重试单个小任务，规避时间缩短。
	
		第一次修改配置转换逻辑代码时间30分钟，规避时间5分钟
	
		以后


​		

###  并行升级特性设计

## 模块设计

## 旧框架设计

升级逻辑应该是简单的，实现是过分复杂的。




## 工程进度

### 详细设计		已完成(2周)

新升级框架整体架构、模块划分、核心模块交互、主要数据结构等设计
模块开发顺序、测试方案等设计

### 设计书评审		进行中(6周)

设计书内部评审

### 模块分工		

按模块分工给具体开发人员，主要有以下四个模块

1. 升级脚本(执行具体升级任务: 下载rpm, 启停组件, 升级rpm等)
2. server任务系统开发(升级任务的顺序编排和下发)
3. client任务执行器开发(接收server下发的命令, 调用相关组件)
4. 外部数据接口(对cps\nova\swift\zookeeper\gaussdb), 内部数据接口(server/client通信)

### 分模块设计		(1周)

与各个模块开发人员对齐模块设计方案和接口

### 工程开发		(15人月)

四大模块并行开发 -> 联调 -> 对接ci\端到端环境验证

# FAQ

## 新框架能否完成升级任务？

## 为什么重写不是重构？

## 旧框架有什么问题？

### 代码问题

### 架构问题

# 附录

## 重点问题

1. N-X升级
2. 可控升级
3. 任意单任务回退
4. 配置转换单独调试
5. 

## 主要数据结构

#### 任务(Task) 

最小的原子化升级任务，一般是指对某个instance进行某个操作。如“节点1的nova-api升级rpm包”

构成元素是host_target_action:

1. host: 

   一般指执行的节点, 如“host1”。全局任务下host为特殊节点“upg-server”。

2. target: 

   任务对象，一般为某个template，如“nova-api”。

3. action: 

   任务动作，如“stop”，“up-rpm”，“start”。

   

   上文“节点1的nova-api升级rpm包”可表示为“host1_nova-api_up-rpm”

   action是原子化细粒度不可分割的。

   > 旧框架: 
   >
   > 	任务是粗粒度、非原子性的。如“升级执行”任务，包括了多批组件的启停、rpm升级、修改配置等多个小任务。
   > 	
   > 	分批关闭组件 -> 修改配置 -> rpm升级 -> 分批开启组件
   >
   > 假如rpm升级工步失败，
   >
   > 	1.	系统只显示“升级执行失败”，需要排除日志才能定位出错点
   > 	
   > 	2.	重试时，需要先重试分批关闭组件、修改配置两个前置工步，才能重试rpm升级
   > 	3.	重试时，pkg内组件无法区分。例如控制节点FusionPlatFrom包内20个组件, 只有一个组件失败了，必须20个组件一起重试
   >
   > 新框架:
   >
   > 	任务是细粒度、原子性的。任务要么全部成功，要么全部失败。
   >
   > 假如rpm升级工步失败，
   >
   >       	1.	系统直接显示“A节点B组件rpm升级失败”
   >                 	2.	重试时，可以直接重试“A节点B组件rpm升级失败”，无需冗余重试前置工步和相关组件
   >
   > 原子性的其它优点这里不赘述。

#### 节点任务(Job)

某个节点一次执行的任务。结构上是Task的2维数组。Job描述了子任务内容、执行顺序和串并行情况。

为了性能考虑，upg-server会对一个upg-client批量下发任务。

```
"""节点任务Job数据结构示例"""
[
	[h1_stop_nova-api, h1_stop_swift-store],
	[h1_uprpm_nova-api, h1_uprpm_swift-store],
	[h1_start_nova-api, h1_start_swift-store]
]
```

如上图，节点h1升级nova-api, swift-store共有6个任务。需要先并行执行关闭2个组件，完成后再并行升级2个组件rpm，完成后再并行打开2个组件。

#### 计划书(Mission)

某个节点一次执行的任务。结构上是Task的4维数组, Job的2维数组。Mission描述了子Job内容、执行顺序和串并行情况。

```
"""节点任务Job数据结构示例"""
[
	[h1_execute_manage_job, h2_execute_manage_job],
	[h1_execute_hostos, h2_execute_hostos],
	[h1_effect_hostos, h2_effect_hostos]
]
```

#### 全局计划书

所有包含升级所有Task的内容和执行顺序

#### 当前计划书
